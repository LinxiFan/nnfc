#!/usr/bin/env python3

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.autograd import Variable

import h5py
import numpy as np
import os
import six
import subprocess as sub

class TinyNet2(nn.Module):
    def __init__(self, num_classes=10):
        super(TinyNet2, self).__init__()

        self.conv1 = nn.Conv2d(3, 3, kernel_size=3, stride=1, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(3)

    def forward(self, x):
        out = self.conv1(x)
        out = self.bn1(out)
        return out

def TinyNet():
    return TinyNet2()

TMPDIR = os.environ['NNFC_TEST_TMPDIR']

batch_size = 1
num_channels = 3
height = 32
width = 32
inputs = Variable(10*torch.randn(batch_size, num_channels, height, width))
print('inputs.shape', inputs.shape)

net = TinyNet()
net.eval()

model_params = net.state_dict()

# for param_name in model_params.keys():
#     shape = model_params[param_name].size()
#     model_params[param_name] = torch.randn(shape)
    
hdf5_file = os.path.join(TMPDIR, 'composed_hl.h5')

with h5py.File(hdf5_file, 'w') as f:
    for param_name in model_params.keys():
        f.create_dataset(param_name, data=model_params[param_name])
            
    f.create_dataset('hdf5_version', data=six.u(h5py.version.hdf5_version))

    outputs = net(inputs)
    f.create_dataset('input', data=inputs.data.numpy().astype(np.float32))
    f.create_dataset('output', data=outputs.data.numpy().astype(np.float32))
    
sub.check_call(['./composed_hl.bin', hdf5_file])
